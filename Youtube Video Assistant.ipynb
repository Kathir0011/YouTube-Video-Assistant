{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Video Assistant\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting Up the API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the API token\n",
    "API_KEY = \"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\"\n",
    "os.environ[\"API_KEY\"] = API_KEY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the YouTube Video Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_from_video_url(video_url):\n",
    "    \"\"\"\n",
    "    Creates an Embedding of the Video and performs \n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=API_KEY)\n",
    "\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "    transcripts = loader.load()\n",
    "    # cannot provide this directly to the model so we are splitting the transcripts into small chunks\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(transcripts)\n",
    "\n",
    "    db = FAISS.from_documents(docs, embedding=embeddings)\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.faiss.FAISS at 0x1a1d18db5e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = create_db_from_video_url(\"https://www.youtube.com/watch?v=C82lT9cWQiA\")\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(api_key, db, request, k=4):\n",
    "    \"\"\"\n",
    "    Usind GPT-3.5-turbo to get the response. It can handle upto 4096 tokens\n",
    "    \"\"\"\n",
    "\n",
    "    docs = db.similarity_search(query=request, k=k)\n",
    "    docs_content = \" \".join([doc.page_content for doc in docs])\n",
    "\n",
    "    chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.2, openai_api_key=api_key)\n",
    "\n",
    "    # creating a template for request\n",
    "    template = \"\"\"\n",
    "    You are an assistant that can answer questions about youtube videos based on\n",
    "    video transcripts: {docs}\n",
    "\n",
    "    Only use factual information from the transcript to answer the question.\n",
    "\n",
    "    If you don't have enough information to answer the question, say \"I don't know\".\n",
    "\n",
    "    Your Answers should be detailed.\n",
    "    \"\"\"\n",
    "\n",
    "    system_msg_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "    # human prompt\n",
    "    human_template = \"Answer the following questions: {question}\"\n",
    "    human_msg_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [system_msg_prompt, human_msg_prompt]\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "\n",
    "    response = chain.run(question=request, docs=docs_content)\n",
    "\n",
    "    return response, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=Q8d4FGWZDbE\"\n",
    "db = create_db_from_video_url(video_url=video_url)\n",
    "\n",
    "request = \"What is he talking about?\"\n",
    "response, docs = get_response(API_KEY, db, request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speaker is talking about a phone, specifically the Xiaomi 13 Ultra, and comparing its camera\n",
      "capabilities to those of other phones, such as the iPhone. He discusses the phone's ability to\n",
      "capture natural skin tones, its limitations in terms of video recording resolution on the front-\n",
      "facing camera, and its impressive rear camera capabilities, including the ability to film 8K video\n",
      "at five times magnification and its night mode. He also mentions the challenges that smartphone\n",
      "cameras have faced in the past and how the Xiaomi 13 Ultra has overcome some of these challenges.\n"
     ]
    }
   ],
   "source": [
    "# using textwrap for printing neatly\n",
    "print(textwrap.fill(response, width=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='if you want to see some more coding challenges or if you want to see the code that series continued drop a comment below and let me know what challenges you think i should be giving a crap thanks again for tuning in guys peace', metadata={'source': 'C82lT9cWQiA'}),\n",
       " Document(page_content=\"what's happening guys welcome to the very first episode of code that a new series where i try to code stuff in a ridiculously short time frame in this episode i'm going to be building and deploying a machine learning api using fast api and scikit learn so what are the rules well first and foremost the time limit you guys were super generous on the community tab and gave me 30 minutes to do this well i'm going to try to do it in 15. second and most importantly i'm not allowed to look at any documentation or stack overflow and no github co-pilot if i do it's a one minute time penalty but the real stakes and the third rule if i fail to make the time limit it's going to be a 50 amazon gift card to you guys so a little bit of background for the guys that aren't so technical what is an api well api stands for application programming interface think of it as the plumbing between different applications in huge organizations they've got a ton of different apis that connect a bunch of stuff\", metadata={'source': 'C82lT9cWQiA'}),\n",
       " Document(page_content=\"that's now ignored we also don't want uh we do want the model to go up we don't want sample.json to go up okay so now we can create or we'll want to commit that so issues there all right so we're going to create a new git repository so get in it get add all git commit m initial commit and then we need to log into heroku so heroku login this might take a little while oh no we've got a minute left um so we need to log in cool we're logged in and then uh what is it so heroku create cool so that's going to create our api and then we want uh git push roku master fingers cross this works all right i'm going to pause the timer all right so we're uploading right now it's building the source but we can't really do anything else so i'm gonna let this run and then [Music] so right now what's happening is we're actually uploading our api like we can't really do very much right now so i figured look i've given myself the benefit of the doubt we've got 35 seconds less left to test if anything goes\", metadata={'source': 'C82lT9cWQiA'}),\n",
       " Document(page_content=\"go and change these values if i change this to 15 years of the company we're getting a different prediction now so zero means the employee hasn't churned this is a churn model so we can change our employee satisfaction value so i can set that to uh we can change the position set that to manager and you can see we're actually capturing those different predictions so salary is an ordinal value between one to five you can see we're making predictions so if we go and drop the years at the company to one you can see that this is saying that's going to churn in that particular case all right not quite 15 minutes but we got super close anyway the amazon gift card's there first one to get it gets it thanks again for tuning in guys hopefully you enjoyed the first episode of code that i'll catch in the next one peace thanks so much for tuning in guys hopefully you've enjoyed this brand new series if you want to see some more coding challenges or if you want to see the code that series continued\", metadata={'source': 'C82lT9cWQiA'})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# video transcripts\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a Gradio Web App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import gradio as gr\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "def create_db_from_video_url(video_url, api_key):\n",
    "    \"\"\"\n",
    "    Creates an Embedding of the Video and makes it suitable for similarity searching.\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "    transcripts = loader.load()\n",
    "    # cannot provide this directly to the model so we are splitting the transcripts into small chunks\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(transcripts)\n",
    "\n",
    "    db = FAISS.from_documents(docs, embedding=embeddings)\n",
    "\n",
    "    return db\n",
    "\n",
    "def get_response(api_key, video_url, request):\n",
    "    \"\"\"\n",
    "    Usind gpt-3.5-turbo to obtain the response. It can handle upto 4096 tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    db = create_db_from_video_url(video_url, api_key)\n",
    "\n",
    "    docs = db.similarity_search(query=request, k=4)\n",
    "    docs_content = \" \".join([doc.page_content for doc in docs])\n",
    "\n",
    "    chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.2, openai_api_key=api_key)\n",
    "\n",
    "    # creating a template for request\n",
    "    template = \"\"\"\n",
    "    You are an assistant that can answer questions about youtube videos based on\n",
    "    video transcripts: {docs}\n",
    "\n",
    "    Only use factual information from the transcript to answer the question.\n",
    "\n",
    "    If you don't have enough information to answer the question, say \"I don't know\".\n",
    "\n",
    "    Your Answers should be detailed.\n",
    "    \"\"\"\n",
    "\n",
    "    system_msg_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "    # human prompt\n",
    "    human_template = \"Answer the following questions: {question}\"\n",
    "    human_msg_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [system_msg_prompt, human_msg_prompt]\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "\n",
    "    response = chain.run(question=request, docs=docs_content)\n",
    "\n",
    "    return response\n",
    "\n",
    "# creating title, description for the web app\n",
    "title = \"YouTube Video Assistant üßë‚Äçüíª\"\n",
    "description = \"Answers to the Questions asked by the user on the specified YouTube video. (English Only)\"\n",
    "article = \"Other Projects:\\n\"\\\n",
    "\"üí∞ [Health Insurance Predictor](http://health-insurance-cost-predictor-k19.streamlit.app/)\\n\"\\\n",
    "\"üì∞ [Fake News Detector](https://fake-news-detector-k19.streamlit.app/)\"\n",
    "# building the app\n",
    "youtube_video_assistant = gr.Interface(\n",
    "    fn=get_response,\n",
    "    inputs=[gr.Text(label=\"Enter the OpenAI API Key:\", placeholder=f\"Example: sk-{'*' * 45}AgM\"), \n",
    "            gr.Text(label=\"Enter the Youtube Video URL:\", placeholder=\"Example: https://www.youtube.com/watch?v=MnDudvCyWpc\"),\n",
    "            gr.Text(label=\"Enter your Question\", placeholder=\"Example: What's the video is about?\")],\n",
    "    outputs=gr.TextArea(label=\"Answers using gpt-3.5-turbo:\"),\n",
    "    title=title,\n",
    "    description=description,\n",
    "    article=article\n",
    ")\n",
    "\n",
    "# launching the web app\n",
    "youtube_video_assistant.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding the deployed app to notebook\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src=, width=800, height=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
