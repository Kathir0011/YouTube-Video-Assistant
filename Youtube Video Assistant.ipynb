{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Video Assistant\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textwrap\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting Up the API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the API token\n",
    "API_KEY = \"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\"\n",
    "os.environ[\"API_KEY\"] = API_KEY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building the YouTube Video Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_from_video_url(video_url):\n",
    "    \"\"\"\n",
    "    Creates an Embedding of the Video and performs \n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=API_KEY)\n",
    "\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "    transcripts = loader.load()\n",
    "    # cannot provide this directly to the model so we are splitting the transcripts into small chunks\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(transcripts)\n",
    "\n",
    "    db = FAISS.from_documents(docs, embedding=embeddings)\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.faiss.FAISS at 0x21549868760>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = create_db_from_video_url(\"https://www.youtube.com/watch?v=C82lT9cWQiA\")\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(api_key, db, request, k=4):\n",
    "    \"\"\"\n",
    "    Usind GPT-3.5-turbo to get the response. It can handle upto 4096 tokens\n",
    "    \"\"\"\n",
    "\n",
    "    docs = db.similarity_search(query=request, k=k)\n",
    "    docs_content = \" \".join([doc.page_content for doc in docs])\n",
    "\n",
    "    chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.2, openai_api_key=api_key)\n",
    "\n",
    "    # creating a template for request\n",
    "    template = \"\"\"\n",
    "    You are an assistant that can answer questions about youtube videos based on\n",
    "    video transcripts: {docs}\n",
    "\n",
    "    Only use factual information from the transcript to answer the question.\n",
    "\n",
    "    If you don't have enough information to answer the question, say \"I don't know\".\n",
    "\n",
    "    Your Answers should be detailed.\n",
    "    \"\"\"\n",
    "\n",
    "    system_msg_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "    # human prompt\n",
    "    human_template = \"Answer the following questions: {question}\"\n",
    "    human_msg_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [system_msg_prompt, human_msg_prompt]\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "\n",
    "    response = chain.run(question=request, docs=docs_content)\n",
    "\n",
    "    return response, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=Q8d4FGWZDbE\"\n",
    "db = create_db_from_video_url(video_url=video_url)\n",
    "\n",
    "request = \"What is he talking about?\"\n",
    "response, docs = get_response(API_KEY, db, request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The speaker is giving a review of the Xiaomi 13 Ultra phone's camera capabilities, both front and\n",
      "rear-facing, based on his experience using it. He discusses the phone's ability to capture natural\n",
      "skin tones, its limitations in terms of video quality and resolution, and its impressive rear camera\n",
      "capabilities, including the ability to capture more light, shoot faster, and create more background\n",
      "blur. He also compares the phone's night mode to that of the iPhone and concludes that the Xiaomi 13\n",
      "Ultra is superior in this regard.\n"
     ]
    }
   ],
   "source": [
    "# using textwrap for printing neatly\n",
    "print(textwrap.fill(response, width=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"pixel have done with their super deep natural skin tones and while this is somewhat rescued by the powerful image processing when you're snapping photos honestly the video is pretty trash I mean look at this room over here it's just it's just a white look plus it's limited to 1080p which I just don't understand like genuinely if there's anyone that showing me watching this video please tell me why this phone your 2023 Pinnacle Flagship Ultra phone cannot record 4k on its front camera it's not a tech limitation phone's been able to do this for years now surely it's not a cost concern they've kitted out every single other camera on the phone all the way to 8K and it can't be anything to do with the size of the cameras either because Samsung does 4K just fine with one that actually takes up less space the only thing I can think is like maybe people feel like 4K might over represent skin imperfections but honestly how your skin looks as much more down to the software processing than it is\", metadata={'source': 'Q8d4FGWZDbE'}),\n",
       " Document(page_content=\"but honestly how your skin looks as much more down to the software processing than it is the resolution you can have sharp footage that also makes you look good like the Samsung that I'm recording this on it might seem like a small nitpicky thing but honestly in an age where everyone is creating content using their smartphones especially this front-facing camera I don't think it is this front camera has probably been the single thing that has actually stopped me from jumping ship all the way from the iPhone because I've very tempted and to understand why I've been so tempted let's talk about the rear cameras and really the best way to Showcase just how great these rear cameras are is not to bind you with a flurry of hundreds of shots taken from it I mean every Flagship from the last five years has been able to take photos like this it's showing you how easy it makes it to do that the key thing that I would say xiaomi have just mastered with this phone is the thoughtlessness everything\", metadata={'source': 'Q8d4FGWZDbE'}),\n",
       " Document(page_content=\"a big thing to say but for all the time that I've used this it hasn't felt like a compromised video experience which is one of those things that I've just come to expect when using an Android phone it's still a little bit grainier in super low light but then on the other hand you can film 8K video at five times magnification yeah it's only 24 FPS so it's a little jittery or cinematic but that's not normal on a phone so xiaomi definitely wins in more categories than the iPhone it doesn't outright mean it's a better phone for everyone like to me the front camera is particularly important and I can't work with this but it is enough for me to say that if you like the sound of it I can very easily recommend it when it launches in your country okay this will be cool actually try filming this on the zoom camera of the phone so recently I've gone into a bit of a rabbit hole when it comes to securing my accounts I've been seeing how even YouTubers who followed all the recommended steps they've\", metadata={'source': 'Q8d4FGWZDbE'}),\n",
       " Document(page_content=\"kind of dumb for this phone I mean the three main challenges that we spent the entire last decade trying to overcome with smartphone cameras are getting more light into these smaller sensors shooting shots faster and creating more background blur to mimic the Cinematic style of professional cameras switching your aperture to F 4.0 basically shuts off your light into each shoots shot slower and reduces background blur I mean there's a couple of super Niche situations where you might want this like long exposure photography but come on when your front camera looks like this fix that first anyways whereas actually even more impressed by this phone was it's night mode Let's be very clear the iPhone is good at night but the xiaomi 13 Ultra feels not like it's kind of close could go either way genuinely like there is no competition like this is a photo from both phones main cameras you can see so many little Parts where the 13 Ultra is just picking up a little bit more information or is a\", metadata={'source': 'Q8d4FGWZDbE'})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# video transcripts\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating a Gradio Web App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio, langchain, openai, faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.28.1', '0.0.157', '0.27.6', '1.7.4')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradio.__version__, langchain.__version__, openai.__version__, faiss.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "gradio==3.28.1\n",
    "langchain==0.0.157\n",
    "openai==0.27.6\n",
    "faiss-cpu==1.7.4\n",
    "youtube_transcript_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import gradio as gr\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "def create_db_from_video_url(video_url, api_key):\n",
    "    \"\"\"\n",
    "    Creates an Embedding of the Video and makes it suitable for similarity searching.\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "\n",
    "    loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "    transcripts = loader.load()\n",
    "    # cannot provide this directly to the model so we are splitting the transcripts into small chunks\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(transcripts)\n",
    "\n",
    "    db = FAISS.from_documents(docs, embedding=embeddings)\n",
    "\n",
    "    return db\n",
    "\n",
    "def get_response(api_key, video_url, request):\n",
    "    \"\"\"\n",
    "    Usind gpt-3.5-turbo to obtain the response. It can handle upto 4096 tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    db = create_db_from_video_url(video_url, api_key)\n",
    "\n",
    "    docs = db.similarity_search(query=request, k=4)\n",
    "    docs_content = \" \".join([doc.page_content for doc in docs])\n",
    "\n",
    "    chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.2, openai_api_key=api_key)\n",
    "\n",
    "    # creating a template for request\n",
    "    template = \"\"\"\n",
    "    You are an assistant that can answer questions about youtube videos based on\n",
    "    video transcripts: {docs}\n",
    "\n",
    "    Only use factual information from the transcript to answer the question.\n",
    "\n",
    "    If you don't have enough information to answer the question, say \"I don't know\".\n",
    "\n",
    "    Your Answers should be detailed.\n",
    "    \"\"\"\n",
    "\n",
    "    system_msg_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "    # human prompt\n",
    "    human_template = \"Answer the following questions: {question}\"\n",
    "    human_msg_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [system_msg_prompt, human_msg_prompt]\n",
    "    )\n",
    "\n",
    "    chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "\n",
    "    response = chain.run(question=request, docs=docs_content)\n",
    "\n",
    "    return response\n",
    "\n",
    "# creating title, description for the web app\n",
    "title = \"YouTube Video Assistant 🧑‍💻\"\n",
    "description = \"Answers to the Questions asked by the user on the specified YouTube video. (English Only)\"\n",
    "article = \"Other Projects:\\n\"\\\n",
    "\"💰 [Health Insurance Predictor](http://health-insurance-cost-predictor-k19.streamlit.app/)\\n\"\\\n",
    "\"📰 [Fake News Detector](https://fake-news-detector-k19.streamlit.app/)\"\n",
    "# building the app\n",
    "youtube_video_assistant = gr.Interface(\n",
    "    fn=get_response,\n",
    "    inputs=[gr.Text(label=\"Enter the OpenAI API Key:\", placeholder=f\"Example: sk-{'*' * 45}AgM\"), \n",
    "            gr.Text(label=\"Enter the Youtube Video URL:\", placeholder=\"Example: https://www.youtube.com/watch?v=MnDudvCyWpc\"),\n",
    "            gr.Text(label=\"Enter your Question\", placeholder=\"Example: What's the video is about?\")],\n",
    "    outputs=gr.TextArea(label=\"Answers using gpt-3.5-turbo:\"),\n",
    "    title=title,\n",
    "    description=description,\n",
    "    article=article\n",
    ")\n",
    "\n",
    "# launching the web app\n",
    "youtube_video_assistant.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"https://kathir0011-youtube-video-assistant.hf.space\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x215011325c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding the deployed app to notebook\n",
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(src=\"https://kathir0011-youtube-video-assistant.hf.space\", width=800, height=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
